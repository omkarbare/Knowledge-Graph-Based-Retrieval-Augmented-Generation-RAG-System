{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Author: Omkar Bare\n",
        "\n",
        "## Project: Knowlegde Graph Based Retrieval-Augmented Generation (RAG) System For U.S. Securities and Exchange Commission (SEC) filings data (Company: NetApp, Inc.)\n",
        "\n",
        "NetApp, Inc. is an American data infrastructure company that provides unified data storage, integrated data services, and cloud operations (CloudOps) solutions to enterprise customers. https://en.wikipedia.org/wiki/NetApp\n",
        "\n",
        "This notebook implements:\n",
        "- construction of nodes for form 10k.\n",
        "- a basic RAG system built without relationship in nodes to chat with the form.\n",
        "\n",
        "Construction of relationship between nodes is done in this notebook:\n",
        "https://colab.research.google.com/drive/13GCkyUvMs42voBzg_3dwyJ4M26iBMVRW?usp=sharing"
      ],
      "metadata": {
        "id": "rPAcEt_n-M_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data used in this project:\n",
        " - SEC Form 10k for company NetApp Inc. (retrieved and stored in `.json` format from SEC website): Publicly traded companies are required to fill a form 10-K each year with the Securities and Exchange Commision (SEC)\n",
        "\n",
        "\n",
        " - SEC Form 13 for the company NetApp Inc. (retrieved and stored in `.csv` format from SEC website): Investment management firms must report on their investments in companies to the SEC by filing a document called **Form 13**"
      ],
      "metadata": {
        "id": "tpyuq22_BaJK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO3RBPrZEeU5"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.18 langchain_community==0.3.17 langchain_openai==0.3.6 openai>=1.6.1 langchain_text_splitters==0.3.6\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "id": "R1q-jijqK6xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "NXbrRmOFIO-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeXc9Z90Et88"
      },
      "outputs": [],
      "source": [
        "# Langchain\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRGrf9vmEuuK"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "NEO4J_URI = userdata.get('NEO4J_URI')\n",
        "NEO4J_USERNAME = userdata.get('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = userdata.get('NEO4J_PASSWORD')\n",
        "NEO4J_DATABASE = userdata.get('NEO4J_DATABASE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxTPLu77FRyJ"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "OPENAI_ENDPOINT = userdata.get('OPENAI_BASE_URL') + '/embeddings'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global constants\n",
        "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
        "VECTOR_NODE_LABEL = 'Chunk'\n",
        "VECTOR_SOURCE_PROPERTY = 'text'\n",
        "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
      ],
      "metadata": {
        "id": "p-FX5SnwPz-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "a-ggRRKOIlq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_name = \"/content/form10k.json\""
      ],
      "metadata": {
        "id": "kLsWVzpaHR63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_as_object = json.load(open(first_file_name))"
      ],
      "metadata": {
        "id": "ZlWtCxc5IM8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(first_file_as_object)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGELQiO6INgx",
        "outputId": "6343873d-2b02-4b49-fa27-1407841f8810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in first_file_as_object.items():\n",
        "    print(k, type(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JH5IonuIZVo",
        "outputId": "0930510c-28d1-4cfa-b93c-6a61b85a8b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item1 <class 'str'>\n",
            "item1a <class 'str'>\n",
            "item7 <class 'str'>\n",
            "item7a <class 'str'>\n",
            "cik <class 'str'>\n",
            "cusip6 <class 'str'>\n",
            "cusip <class 'list'>\n",
            "names <class 'list'>\n",
            "source <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")"
      ],
      "metadata": {
        "id": "-x7nAs1LIgM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text_chunks = text_splitter.split_text(item1_text)"
      ],
      "metadata": {
        "id": "VM1HDDS5IuX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(item1_text_chunks), len(item1_text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na-oYsAwIxHf",
        "outputId": "8c803672-afc7-436b-e0ba-c355bdba13f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 254)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking"
      ],
      "metadata": {
        "id": "4Taz9PoF27is"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Set up helper function to chunk all sections of the Form 10-K"
      ],
      "metadata": {
        "id": "NKG1t6r3JFGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_form10k_data_from_file(file):\n",
        "    \"\"\"\n",
        "    Helper function for chunking all sections of te=he form 10-k\n",
        "    \"\"\"\n",
        "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
        "    file_as_object = json.load(open(file)) # open the json file\n",
        "\n",
        "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
        "        print(f'Processing {item} from {file}')\n",
        "        item_text = file_as_object[item] # grab the text of the item\n",
        "        item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
        "        chunk_seq_id = 0\n",
        "\n",
        "        for chunk in item_text_chunks:\n",
        "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
        "            # finally, construct a record with metadata and the chunk text\n",
        "            chunks_with_metadata.append({\n",
        "                'text': chunk,\n",
        "                # metadata from looping...\n",
        "                'f10kItem': item,\n",
        "                'chunkSeqId': chunk_seq_id,\n",
        "                # constructed metadata...\n",
        "                'formId': f'{form_id}', # pulled from the filename\n",
        "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
        "                # metadata from file...\n",
        "                'names': file_as_object['names'],\n",
        "                'cik': file_as_object['cik'],\n",
        "                'cusip6': file_as_object['cusip6'],\n",
        "                'source': file_as_object['source'],\n",
        "            })\n",
        "            chunk_seq_id += 1\n",
        "        print(f'\\tSplit into {chunk_seq_id} chunks')\n",
        "    return chunks_with_metadata"
      ],
      "metadata": {
        "id": "eN8mOHu5I1q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_chunks = split_form10k_data_from_file(first_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFSieL6AJSgI",
        "outputId": "c4095242-5dcc-4aa8-8d12-5170f8001fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing item1 from /content/0000950170-23-027948.json\n",
            "\tSplit into 254 chunks\n",
            "Processing item1a from /content/0000950170-23-027948.json\n",
            "\tSplit into 1 chunks\n",
            "Processing item7 from /content/0000950170-23-027948.json\n",
            "\tSplit into 1 chunks\n",
            "Processing item7a from /content/0000950170-23-027948.json\n",
            "\tSplit into 1 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWtI7uQjJUiq",
        "outputId": "c6c89eed-c3ea-4710-93ac-bb6e62b1603e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud environment are:\\n\\n\\n•\\nOperational simplicity: NetApp’s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\n•\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.',\n",
              " 'f10kItem': 'item1',\n",
              " 'chunkSeqId': 0,\n",
              " 'formId': '0000950170-23-027948',\n",
              " 'chunkId': '0000950170-23-027948-item1-chunk0000',\n",
              " 'names': ['Netapp Inc', 'NETAPP INC'],\n",
              " 'cik': '1002047',\n",
              " 'cusip6': '64110D',\n",
              " 'source': 'https://www.sec.gov/Archives/edgar/data/1002047/000095017023027948/0000950170-23-027948-index.htm'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create graph nodes"
      ],
      "metadata": {
        "id": "UxSvzhH3KABJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is what the below query does step-by-step:\n",
        "\n",
        "- MERGE(mergedChunk:Chunk `{chunkId: $chunkParam.chunkId})`: This tries to find a node labeled Chunk with the property chunkId equal to the value provided in $chunkParam.chunkId. If such a node exists, it matches it and binds it to the variable mergedChunk. If it does not exist, it creates a new Chunk node with that chunkId.\n",
        "\n",
        "- ON CREATE SET: This block runs only when a new node is created by the MERGE (not found existing). It sets additional properties on the newly created node mergedChunk from the values inside the parameter $chunkParam. These properties include names, formId, cik, cusip6, source, f10kItem, chunkSeqId, and text.\n",
        "\n",
        "- RETURN mergedChunk: After creating or matching the node, the query returns the mergedChunk node."
      ],
      "metadata": {
        "id": "oXBlXomGKZVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_chunk_node_query = \"\"\"\n",
        "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
        "    ON CREATE SET\n",
        "        mergedChunk.names = $chunkParam.names,\n",
        "        mergedChunk.formId = $chunkParam.formId,\n",
        "        mergedChunk.cik = $chunkParam.cik,\n",
        "        mergedChunk.cusip6 = $chunkParam.cusip6,\n",
        "        mergedChunk.source = $chunkParam.source,\n",
        "        mergedChunk.f10kItem = $chunkParam.f10kItem,\n",
        "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId,\n",
        "        mergedChunk.text = $chunkParam.text\n",
        "RETURN mergedChunk\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gFcHV7h8JaCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Set up connection to graph instance using LangChain"
      ],
      "metadata": {
        "id": "WLJ_3RRmK0zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg = Neo4jGraph(\n",
        "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
        ")"
      ],
      "metadata": {
        "id": "l8ENX-5DKa_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a single chunk node for now"
      ],
      "metadata": {
        "id": "52AY6IjaLHEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(merge_chunk_node_query,\n",
        "         params={'chunkParam':first_file_chunks[0]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rYbQnM5K2ro",
        "outputId": "605bcb7a-12f6-45f1-cbab-52f0864a8a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'mergedChunk': {'formId': '0000950170-23-027948',\n",
              "   'f10kItem': 'item1',\n",
              "   'names': ['Netapp Inc', 'NETAPP INC'],\n",
              "   'cik': '1002047',\n",
              "   'cusip6': '64110D',\n",
              "   'source': 'https://www.sec.gov/Archives/edgar/data/1002047/000095017023027948/0000950170-23-027948-index.htm',\n",
              "   'text': '>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud environment are:\\n\\n\\n•\\nOperational simplicity: NetApp’s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\n•\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.',\n",
              "   'chunkId': '0000950170-23-027948-item1-chunk0000',\n",
              "   'chunkSeqId': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a uniqueness constraint to avoid duplicate chunks"
      ],
      "metadata": {
        "id": "7HhsYfH4LTv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "CREATE CONSTRAINT unique_chunk IF NOT EXISTS\n",
        "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tu7BbZXLUEg",
        "outputId": "d2f8913d-9878-4af1-d1e7-956501b3a2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- list all the indexes currently defined in the Neo4j graph database"
      ],
      "metadata": {
        "id": "WJ3vzm7RLplk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiNzwBVpLWX_",
        "outputId": "6a472b97-e4ff-4172-c5e3-40314d2b60d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 1,\n",
              "  'name': 'index_1b9dcc97',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'RELATIONSHIP',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 0,\n",
              "  'name': 'index_460996c0',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 2,\n",
              "  'name': 'unique_chunk',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'RANGE',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Chunk'],\n",
              "  'properties': ['chunkId'],\n",
              "  'indexProvider': 'range-1.0',\n",
              "  'owningConstraint': 'unique_chunk',\n",
              "  'lastRead': None,\n",
              "  'readCount': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Loop through and create nodes for all chunks"
      ],
      "metadata": {
        "id": "lukNgpERLtPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_count = 0\n",
        "for chunk in first_file_chunks:\n",
        "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkId']}\")\n",
        "    kg.query(merge_chunk_node_query,\n",
        "            params={\n",
        "                'chunkParam': chunk\n",
        "            })\n",
        "    node_count += 1\n",
        "print(f\"Created {node_count} nodes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwZJZXbeLY7W",
        "outputId": "c9122a27-b156-4fd3-8a86-34f5a4b09bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0000\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0001\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0002\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0003\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0004\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0005\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0006\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0007\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0008\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0009\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0010\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0011\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0012\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0013\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0014\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0015\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0016\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0017\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0018\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0019\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0020\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0021\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0022\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0023\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0024\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0025\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0026\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0027\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0028\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0029\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0030\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0031\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0032\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0033\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0034\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0035\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0036\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0037\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0038\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0039\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0040\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0041\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0042\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0043\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0044\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0045\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0046\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0047\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0048\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0049\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0050\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0051\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0052\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0053\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0054\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0055\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0056\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0057\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0058\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0059\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0060\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0061\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0062\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0063\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0064\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0065\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0066\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0067\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0068\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0069\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0070\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0071\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0072\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0073\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0074\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0075\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0076\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0077\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0078\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0079\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0080\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0081\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0082\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0083\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0084\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0085\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0086\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0087\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0088\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0089\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0090\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0091\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0092\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0093\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0094\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0095\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0096\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0097\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0098\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0099\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0100\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0101\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0102\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0103\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0104\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0105\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0106\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0107\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0108\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0109\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0110\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0111\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0112\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0113\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0114\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0115\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0116\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0117\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0118\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0119\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0120\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0121\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0122\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0123\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0124\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0125\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0126\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0127\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0128\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0129\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0130\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0131\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0132\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0133\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0134\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0135\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0136\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0137\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0138\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0139\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0140\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0141\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0142\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0143\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0144\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0145\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0146\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0147\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0148\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0149\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0150\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0151\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0152\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0153\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0154\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0155\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0156\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0157\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0158\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0159\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0160\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0161\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0162\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0163\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0164\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0165\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0166\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0167\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0168\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0169\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0170\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0171\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0172\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0173\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0174\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0175\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0176\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0177\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0178\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0179\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0180\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0181\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0182\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0183\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0184\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0185\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0186\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0187\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0188\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0189\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0190\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0191\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0192\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0193\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0194\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0195\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0196\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0197\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0198\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0199\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0200\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0201\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0202\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0203\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0204\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0205\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0206\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0207\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0208\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0209\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0210\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0211\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0212\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0213\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0214\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0215\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0216\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0217\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0218\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0219\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0220\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0221\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0222\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0223\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0224\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0225\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0226\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0227\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0228\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0229\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0230\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0231\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0232\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0233\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0234\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0235\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0236\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0237\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0238\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0239\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0240\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0241\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0242\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0243\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0244\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0245\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0246\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0247\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0248\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0249\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0250\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0251\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0252\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0253\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1a-chunk0000\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item7-chunk0000\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item7a-chunk0000\n",
            "Created 257 nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "         MATCH (n)\n",
        "         RETURN count(n) as nodeCount\n",
        "         \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LFLHIsRLwiC",
        "outputId": "3d6a6ae7-1dd3-495f-dabd-3b8f2c5a027a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'nodeCount': 257}]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a vector index"
      ],
      "metadata": {
        "id": "XgcD4w6wMZ64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A vector index in Neo4j is a specialized type of index designed to facilitate efficient similarity searches based on high-dimensional vector representations of data, often embeddings generated by machine learning models. Unlike traditional indexes that rely on exact property matches, vector indexes support approximate nearest neighbor (ANN) searches, which quickly identify the most similar nodes or relationships based on their embedded vectors."
      ],
      "metadata": {
        "id": "E2kxSE9NMsh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
        "          FOR (c:Chunk) ON (c.textEmbedding)\n",
        "          OPTIONS { indexConfig: {\n",
        "            `vector.dimensions`: 1536,\n",
        "            `vector.similarity_function`: 'cosine'\n",
        "         }}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-yX8SH-Mbu0",
        "outputId": "2efa6058-70c1-42c1-a0c9-a2abbb84c2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqedUHtYMzBf",
        "outputId": "706ab2bb-3998-479b-942b-14b8d821661b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 4,\n",
              "  'name': 'form_10k_chunks',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'VECTOR',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Chunk'],\n",
              "  'properties': ['textEmbedding'],\n",
              "  'indexProvider': 'vector-3.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 1,\n",
              "  'name': 'index_1b9dcc97',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'RELATIONSHIP',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 0,\n",
              "  'name': 'index_460996c0',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 2,\n",
              "  'name': 'unique_chunk',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'RANGE',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Chunk'],\n",
              "  'properties': ['chunkId'],\n",
              "  'indexProvider': 'range-1.0',\n",
              "  'owningConstraint': 'unique_chunk',\n",
              "  'lastRead': neo4j.time.DateTime(2025, 11, 5, 4, 4, 17, 263000000, tzinfo=<UTC>),\n",
              "  'readCount': 769}]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate embedding vectors for chunks and populate index\n",
        "- This query calculates the embedding vector and stores it as a property called `textEmbedding` on each `Chunk` node."
      ],
      "metadata": {
        "id": "V-6W6WAlNOHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
        "    WITH chunk, genai.vector.encode(\n",
        "      chunk.text,\n",
        "      \"OpenAI\",\n",
        "      {\n",
        "        token: $openAiApiKey,\n",
        "        endpoint: $openAiEndpoint\n",
        "      }) AS vector\n",
        "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
        "    \"\"\",\n",
        "    params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db6bzeN1MzXg",
        "outputId": "2461a57e-2742-442c-bd86-4c76ef41e37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.refresh_schema()\n",
        "print(kg.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aavSeUZTNRUw",
        "outputId": "efd16fae-92e8-4c18-b8f1-d5fd1b799d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties:\n",
            "Chunk {chunkId: STRING, names: LIST, formId: STRING, cik: STRING, cusip6: STRING, source: STRING, f10kItem: STRING, chunkSeqId: INTEGER, text: STRING, textEmbedding: LIST}\n",
            "Relationship properties:\n",
            "\n",
            "The relationships:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Setup a help function to perform similarity search using the vector index"
      ],
      "metadata": {
        "id": "YDMK3UKwPqNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neo4j_vector_search(question):\n",
        "  \"\"\"\n",
        "  Search for similar nodes using the Neo4j vector index.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  vector_search_query = \"\"\"\n",
        "    WITH genai.vector.encode(\n",
        "      $question,\n",
        "      \"OpenAI\",\n",
        "      {\n",
        "        token: $openAiApiKey,\n",
        "        endpoint: $openAiEndpoint\n",
        "      }) AS question_embedding\n",
        "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
        "    RETURN score, node.text AS text\n",
        "  \"\"\"\n",
        "  similar = kg.query(vector_search_query,\n",
        "                     params={\n",
        "                      'question': question,\n",
        "                      'openAiApiKey':OPENAI_API_KEY,\n",
        "                      'openAiEndpoint': OPENAI_ENDPOINT,\n",
        "                      'index_name':VECTOR_INDEX_NAME,\n",
        "                      'top_k': 10})\n",
        "  return similar"
      ],
      "metadata": {
        "id": "v1tSVNCBPltD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = neo4j_vector_search(\n",
        "    'In a single sentence, tell me about Netapp.'\n",
        ")"
      ],
      "metadata": {
        "id": "WqKxwCIhPsuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8TkVTDcPvVG",
        "outputId": "ee197b46-34f1-46d8-ddf5-bed71b2d0cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.93023681640625,\n",
              " 'text': '>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud environment are:\\n\\n\\n•\\nOperational simplicity: NetApp’s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\n•\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.'}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up for Basic LangChain RAG workflow without relationship in nodes to chat with the form"
      ],
      "metadata": {
        "id": "jBTtx7hwQKxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
        "    embedding=OpenAIEmbeddings(api_key=OPENAI_API_KEY),\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USERNAME,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    index_name=VECTOR_INDEX_NAME,\n",
        "    node_label=VECTOR_NODE_LABEL,\n",
        "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
        "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
        ")"
      ],
      "metadata": {
        "id": "ROgam_GmP5Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = neo4j_vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "DdHQM_FhQM_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`RetrievalQAWithSourcesChain` in LangChain is a chain class designed for question-answering (QA) tasks that combines document retrieval with answering while explicitly returning the source documents that support the answer."
      ],
      "metadata": {
        "id": "f2vTTANyRB5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    ChatOpenAI(temperature=0, api_key=OPENAI_API_KEY),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "BG4xASV2QjEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettychain(question: str) -> str:\n",
        "    \"\"\"\n",
        "    print the chain's response to a question.\n",
        "    \"\"\"\n",
        "    response = chain({\"question\": question},\n",
        "        return_only_outputs=True,)\n",
        "    print(textwrap.fill(response['answer'], 60))"
      ],
      "metadata": {
        "id": "0M1KhYJ7SKLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Netapp's primary business?\"\n",
        "prettychain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv1uFtUERYDt",
        "outputId": "243ffe84-7240-4188-94cc-bdadf63ca1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetApp's primary business is enterprise storage and data\n",
            "management, cloud storage, and cloud operations.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}